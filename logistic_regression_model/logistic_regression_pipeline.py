# -*- coding: utf-8 -*-
"""Untitled77.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t5tZAHAyghpg8bPZc1HT2pktvo8BlYNU
"""

import joblib
import pandas as pd
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
import seaborn as sns
import matplotlib.pyplot as plt
from preprocessing.text_processing_and_feature_engineering import *

class LogisticRegressionEvaluationPipeline:
    selected_features = [
        'title_char_count', 'question_mark_ratio', 'exclamation_mark_ratio',
        'ellipses_ratio', 'comma_ratio', 'url_count_ratio', 'period_ratio',
        'symbol_to_word_ratio', 'at_ratio', 'quote_ratio', 'hashtag_ratio',
        'exclamation_mark_count_text', 'ellipses_count_text', 'stop_word_count_title'
    ]

    def __init__(self, model_dir="logistic_regression_model", features_to_drop=None):
        default_features_to_drop = [
            "month", "year", "cluster", "numeric_label",
            "title_word_count", "title_unique_word_count", "special_char_ratio_text",
            "unique_word_count", "word_count", "special_char_ratio",
            "capital_letters_ratio_text", "sentence_count"
        ]
        self.features_to_drop = features_to_drop or default_features_to_drop

        self.model_path = f"{model_dir}/logistic_regression_model.pkl"
        self.scaler_path = f"{model_dir}/scaler.pkl"

        self.model = joblib.load(self.model_path)
        self.scaler = joblib.load(self.scaler_path)

    def preprocess_and_clean(self, data):
        processed_data = preprocess_and_engineer_features(data)
        numeric_data = processed_data.select_dtypes(include=["float64", "int64"]).copy()
        cleaned_data = numeric_data.drop(columns=self.features_to_drop, errors="ignore")

        return cleaned_data

    def preprocess_and_scale(self, data):
        cleaned_data = self.preprocess_and_clean(data)

        scaled_data = pd.DataFrame(
            self.scaler.transform(cleaned_data),
            columns=cleaned_data.columns,
            index=cleaned_data.index
        )
        return scaled_data

    def preprocess_and_select_features(self, data):
        scaled_data = self.preprocess_and_scale(data)
        selected_data = scaled_data[self.selected_features]

        return selected_data

    def predict(self, data):
        processed_data = self.preprocess_and_select_features(data)
        predictions = self.model.predict(processed_data)
        probabilities = self.model.predict_proba(processed_data)[:, 1]

        return {
            "predictions": predictions,
            "probabilities": probabilities
        }

    def evaluate(self, data, true_labels):
        results = self.predict(data)
        predictions = results["predictions"]
        probabilities = results["probabilities"]

        report = classification_report(true_labels, predictions)
        conf_matrix = confusion_matrix(true_labels, predictions)
        roc_auc = roc_auc_score(true_labels, probabilities)

        plt.figure(figsize=(8, 6))
        sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=["False", "True"], yticklabels=["False", "True"])
        plt.title("Confusion Matrix", fontsize=16)
        plt.xlabel("Predicted Label", fontsize=14)
        plt.ylabel("True Label", fontsize=14)
        plt.show()

        fpr, tpr, _ = roc_curve(true_labels, probabilities)
        plt.figure(figsize=(8, 6))
        plt.plot(fpr, tpr, label=f"ROC-AUC score: {roc_auc:.2f}", color="darkorange", lw=2)
        plt.plot([0, 1], [0, 1], color="navy", lw=2, linestyle="--")
        plt.xlabel("False Positive Rate", fontsize=12)
        plt.ylabel("True Positive Rate", fontsize=12)
        plt.title("ROC Curve", fontsize=16)
        plt.legend(loc="lower right")
        plt.grid(alpha=0.3)
        plt.show()

        return {
            "classification_report": report,
            "confusion_matrix": conf_matrix,
            "roc_auc": roc_auc
        }